{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>heading</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>bias_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>['Protests', 'Fourth Of July', 'Gun Control An...</td>\n",
       "      <td>Chicago Gun Violence Spikes and Increasingly F...</td>\n",
       "      <td>New York Times (News)</td>\n",
       "      <td>As Yasmin Miller drove home from a laundromat ...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>['Protests', 'Fourth Of July', 'Gun Control An...</td>\n",
       "      <td>‘Bullets just came from nowhere’: Fourth of Ju...</td>\n",
       "      <td>Chicago Tribune</td>\n",
       "      <td>As many Chicagoans were celebrating the Fourth...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>['Protests', 'Fourth Of July', 'Gun Control An...</td>\n",
       "      <td>Dozens of shootings across US mark bloody July...</td>\n",
       "      <td>New York Post (News)</td>\n",
       "      <td>The nation’s 4th of July weekend was marred by...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yellen Warns Congress of 'Economic Recession' ...</td>\n",
       "      <td>['Janet Yellen', 'Debt Ceiling', 'Economic Pol...</td>\n",
       "      <td>Federal Government Will Run Out of Cash on Oct...</td>\n",
       "      <td>The Epoch Times</td>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday war...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yellen Warns Congress of 'Economic Recession' ...</td>\n",
       "      <td>['Janet Yellen', 'Debt Ceiling', 'Economic Pol...</td>\n",
       "      <td>Yellen tells Congress that U.S. will run out o...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday tol...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0           Gun Violence Over Fourth of July Weekend   \n",
       "1           1           Gun Violence Over Fourth of July Weekend   \n",
       "2           2           Gun Violence Over Fourth of July Weekend   \n",
       "3           3  Yellen Warns Congress of 'Economic Recession' ...   \n",
       "4           4  Yellen Warns Congress of 'Economic Recession' ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Protests', 'Fourth Of July', 'Gun Control An...   \n",
       "1  ['Protests', 'Fourth Of July', 'Gun Control An...   \n",
       "2  ['Protests', 'Fourth Of July', 'Gun Control An...   \n",
       "3  ['Janet Yellen', 'Debt Ceiling', 'Economic Pol...   \n",
       "4  ['Janet Yellen', 'Debt Ceiling', 'Economic Pol...   \n",
       "\n",
       "                                             heading                 source  \\\n",
       "0  Chicago Gun Violence Spikes and Increasingly F...  New York Times (News)   \n",
       "1  ‘Bullets just came from nowhere’: Fourth of Ju...        Chicago Tribune   \n",
       "2  Dozens of shootings across US mark bloody July...   New York Post (News)   \n",
       "3  Federal Government Will Run Out of Cash on Oct...        The Epoch Times   \n",
       "4  Yellen tells Congress that U.S. will run out o...        Washington Post   \n",
       "\n",
       "                                                text bias_rating  \n",
       "0  As Yasmin Miller drove home from a laundromat ...        left  \n",
       "1  As many Chicagoans were celebrating the Fourth...      center  \n",
       "2  The nation’s 4th of July weekend was marred by...       right  \n",
       "3  Treasury Secretary Janet Yellen on Tuesday war...       right  \n",
       "4  Treasury Secretary Janet Yellen on Tuesday tol...        left  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV file\n",
    "file_path = '/Users/miriam/Documents/GitHub/Qbias/allsides_balanced_news_headlines-texts.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21754 entries, 0 to 21753\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        21754 non-null  object\n",
      " 1   tags         21754 non-null  object\n",
      " 2   heading      21754 non-null  object\n",
      " 3   source       21746 non-null  object\n",
      " 4   text         21754 non-null  object\n",
      " 5   bias_rating  21754 non-null  object\n",
      " 6   clean_text   21754 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert non-string values to empty string for the 'text' column\n",
    "data['text'] = data['text'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Clean the text column again\n",
    "data['text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned data summary\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As Yasmin Miller drove home from a laundromat ...</td>\n",
       "      <td>as yasmin miller drove home from a laundromat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As many Chicagoans were celebrating the Fourth...</td>\n",
       "      <td>as many chicagoans were celebrating the fourth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The nation’s 4th of July weekend was marred by...</td>\n",
       "      <td>the nations th of july weekend was marred by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday war...</td>\n",
       "      <td>treasury secretary janet yellen on tuesday war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday tol...</td>\n",
       "      <td>treasury secretary janet yellen on tuesday tol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  As Yasmin Miller drove home from a laundromat ...   \n",
       "1  As many Chicagoans were celebrating the Fourth...   \n",
       "2  The nation’s 4th of July weekend was marred by...   \n",
       "3  Treasury Secretary Janet Yellen on Tuesday war...   \n",
       "4  Treasury Secretary Janet Yellen on Tuesday tol...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  as yasmin miller drove home from a laundromat ...  \n",
       "1  as many chicagoans were celebrating the fourth...  \n",
       "2  the nations th of july weekend was marred by t...  \n",
       "3  treasury secretary janet yellen on tuesday war...  \n",
       "4  treasury secretary janet yellen on tuesday tol...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Clean the text column\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # Lowercase text\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)  # Remove special characters and digits\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "        return text\n",
    "    return \"\"\n",
    "\n",
    "# Apply cleaning to the 'text' column\n",
    "data['clean_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Display a sample of the cleaned text\n",
    "data[['text', 'clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>spacy_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as yasmin miller drove home from a laundromat ...</td>\n",
       "      <td>[as, yasmin, miller, drove, home, from, a, lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as many chicagoans were celebrating the fourth...</td>\n",
       "      <td>[as, many, chicagoans, were, celebrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the nations th of july weekend was marred by t...</td>\n",
       "      <td>[the, nations, th, of, july, weekend, was, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>treasury secretary janet yellen on tuesday war...</td>\n",
       "      <td>[treasury, secretary, janet, yellen, on, tuesd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treasury secretary janet yellen on tuesday tol...</td>\n",
       "      <td>[treasury, secretary, janet, yellen, on, tuesd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  as yasmin miller drove home from a laundromat ...   \n",
       "1  as many chicagoans were celebrating the fourth...   \n",
       "2  the nations th of july weekend was marred by t...   \n",
       "3  treasury secretary janet yellen on tuesday war...   \n",
       "4  treasury secretary janet yellen on tuesday tol...   \n",
       "\n",
       "                                        spacy_tokens  \n",
       "0  [as, yasmin, miller, drove, home, from, a, lau...  \n",
       "1  [as, many, chicagoans, were, celebrating, the,...  \n",
       "2  [the, nations, th, of, july, weekend, was, mar...  \n",
       "3  [treasury, secretary, janet, yellen, on, tuesd...  \n",
       "4  [treasury, secretary, janet, yellen, on, tuesd...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install spaCy and download the English model\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load spaCy's English tokenizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenize using spaCy\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_punct and not token.is_space]\n",
    "\n",
    "# Apply spaCy tokenizer to clean text\n",
    "data['spacy_tokens'] = data['clean_text'].apply(spacy_tokenizer)\n",
    "\n",
    "# Display sample data\n",
    "data[['clean_text', 'spacy_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacy_tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[as, yasmin, miller, drove, home, from, a, lau...</td>\n",
       "      <td>[yasmin, miller, drove, home, laundromat, chic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[as, many, chicagoans, were, celebrating, the,...</td>\n",
       "      <td>[many, chicagoans, celebrating, fourth, july, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[the, nations, th, of, july, weekend, was, mar...</td>\n",
       "      <td>[nations, th, july, weekend, marred, wrong, ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[treasury, secretary, janet, yellen, on, tuesd...</td>\n",
       "      <td>[treasury, secretary, janet, yellen, tuesday, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[treasury, secretary, janet, yellen, on, tuesd...</td>\n",
       "      <td>[treasury, secretary, janet, yellen, tuesday, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        spacy_tokens  \\\n",
       "0  [as, yasmin, miller, drove, home, from, a, lau...   \n",
       "1  [as, many, chicagoans, were, celebrating, the,...   \n",
       "2  [the, nations, th, of, july, weekend, was, mar...   \n",
       "3  [treasury, secretary, janet, yellen, on, tuesd...   \n",
       "4  [treasury, secretary, janet, yellen, on, tuesd...   \n",
       "\n",
       "                                     filtered_tokens  \n",
       "0  [yasmin, miller, drove, home, laundromat, chic...  \n",
       "1  [many, chicagoans, celebrating, fourth, july, ...  \n",
       "2  [nations, th, july, weekend, marred, wrong, ki...  \n",
       "3  [treasury, secretary, janet, yellen, tuesday, ...  \n",
       "4  [treasury, secretary, janet, yellen, tuesday, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a minimal list of English stopwords\n",
    "manual_stopwords = set([\"the\", \"a\", \"an\", \"is\", \"it\", \"to\", \"and\", \"in\", \"on\", \"for\", \"with\", \"of\", \"at\", \"by\", \"from\", \"as\", \"were\", \"was\", \"this\"])\n",
    "\n",
    "# Remove stopwords from tokens\n",
    "data['filtered_tokens'] = data['spacy_tokens'].apply(lambda x: [word for word in x if word not in manual_stopwords])\n",
    "\n",
    "# Display sample data\n",
    "data[['spacy_tokens', 'filtered_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('background', 0.7790801525115967),\n",
       " ('control', 0.7700991034507751),\n",
       " ('violence', 0.7597283720970154),\n",
       " ('stiffen', 0.7140454649925232),\n",
       " ('purchasers', 0.7134820222854614),\n",
       " ('birth', 0.7109858989715576),\n",
       " ('advocates', 0.6902703642845154),\n",
       " ('checks', 0.6894843578338623),\n",
       " ('parental', 0.6825336813926697),\n",
       " ('spiraled', 0.679111123085022)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Step 1: Train Word2Vec embeddings on the filtered tokens\n",
    "word2vec_model = Word2Vec(sentences=data['filtered_tokens'], vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Step 2: Check the nearest neighbors for the word \"gun\"\n",
    "if \"gun\" in word2vec_model.wv:\n",
    "    similar_words = word2vec_model.wv.most_similar(\"gun\", topn=10)\n",
    "else:\n",
    "    similar_words = \"Word 'gun' not found in vocabulary.\"\n",
    "\n",
    "similar_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.2-cp39-cp39-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Using cached h5py-3.12.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Using cached optree-0.13.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/miriam/miniconda3/envs/style-change/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.16.2-cp39-cp39-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp39-cp39-macosx_10_9_universal2.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached h5py-3.12.1-cp39-cp39-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl (389 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.13.1-cp39-cp39-macosx_10_9_universal2.whl (576 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, markdown, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 protobuf-4.25.5 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "!pip install tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Prepare the data for training\n",
    "# Define constants\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['clean_text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['clean_text'])\n",
    "\n",
    "# Pad sequences\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Encode the labels\n",
    "label_mapping = {'left': 0, 'center': 1, 'right': 2}\n",
    "y = data['bias_rating'].map(label_mapping).values\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 2: Build the Neural Network\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['clean_text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['clean_text'])\n",
    "\n",
    "# Pad sequences\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Encode the labels\n",
    "label_mapping = {'left': 0, 'center': 1, 'right': 2}\n",
    "y = data['bias_rating'].map(label_mapping).values\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 2: Build the Neural Network\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "style-change",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
